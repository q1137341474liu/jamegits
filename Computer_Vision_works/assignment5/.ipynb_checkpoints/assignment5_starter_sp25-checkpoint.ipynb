{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR0SKBDbaOqR"
      },
      "source": [
        "# MP5: Training Your Diffusion Model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryMrLOORbWLz"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdFQ6c9-Pm4Y"
      },
      "outputs": [],
      "source": [
        "# Import essential modules. Feel free to add whatever you need.\n",
        "import matplotlib.pyplot as plt\n",
        "import torch # added\n",
        "from torch import optim # added\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qCe1sbsTlSC"
      },
      "outputs": [],
      "source": [
        "def visualize_images_with_titles(images: torch.Tensor, column_names: list[str]):\n",
        "    \"\"\"\n",
        "    Visualize images as a grid and title the columns with the provided names.\n",
        "\n",
        "    Args:\n",
        "        images: (N, C, H, W) tensor of images, where N is (number of rows * number of columns)\n",
        "        column_names: List of column names for the titles.\n",
        "\n",
        "    Example usage:\n",
        "    visualize_images_with_titles(torch.randn(16, 1, 32, 32), ['1', '2', '3', '4'])\n",
        "    \"\"\"\n",
        "    num_images, num_columns = images.shape[0], len(column_names)\n",
        "    assert num_images % num_columns == 0, 'Number of images must be a multiple of the number of columns.'\n",
        "\n",
        "    num_rows = num_images // num_columns\n",
        "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(num_columns * 1, num_rows * 1))\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        img = images[i].permute(1, 2, 0).cpu().numpy()\n",
        "        ax.imshow(img, cmap='gray')\n",
        "        ax.axis('off')\n",
        "        if i < num_columns:\n",
        "            ax.set_title(column_names[i % num_columns])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZZziMrxiIk"
      },
      "source": [
        "# Part 1: Training a Single-step Denoising UNet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dokvxybn_DwK"
      },
      "source": [
        "## Implementing Simple and Composed Ops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhpEzgwCJqbW"
      },
      "outputs": [],
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class DownConv(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class UpConv(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class Unflatten(nn.Module):\n",
        "    def __init__(self, in_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsntLNl8PkdG"
      },
      "source": [
        "## Implementing Unconditional UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94h1Q3BxN0ha"
      },
      "outputs": [],
      "source": [
        "class UnconditionalUNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        num_hiddens: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        assert x.shape[-2:] == (28, 28), \"Expect input shape to be (28, 28).\"\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itmHM7udTlSD"
      },
      "source": [
        "## Visualizing the noising process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "WFhyA6joTlSD",
        "outputId": "9ba8b0ac-fd7c-413f-e4d3-8a9ad2bf029a"
      },
      "outputs": [],
      "source": [
        "dataset = MNIST(root=\"data\", download=True, transform=ToTensor(), train=True)\n",
        "\n",
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4mNfCUETlSE"
      },
      "source": [
        "## Training a Single-Step Unconditional UNet\n",
        "\n",
        "- Plot the loss curve\n",
        "- Sample results on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "CFnYvvmWTlSE",
        "outputId": "b3267805-6f30-4873-b25b-d7e0118e2b13"
      },
      "outputs": [],
      "source": [
        "dataset = MNIST(root='data', download=True, transform=ToTensor(), train=True)\n",
        "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
        "\n",
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFvFEa0uTlSF"
      },
      "source": [
        "## Out-of-Distribution Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "BUb-JMHrTlSF",
        "outputId": "356b18cc-5c1d-4e00-93b2-20e7262ccc2b"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ObcO_jUamVE"
      },
      "source": [
        "# Part 2: Training a Diffusion Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMI3IMkjayxQ"
      },
      "source": [
        "## Implementing a Time-conditioned UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkchbyYkzAvV"
      },
      "outputs": [],
      "source": [
        "class FCBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class TimeConditionalUNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        num_classes: int,\n",
        "        num_hiddens: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        t: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "            t: (N,) normalized time tensor.\n",
        "\n",
        "        Returns:\n",
        "            (N, C, H, W) output tensor.\n",
        "        \"\"\"\n",
        "        assert x.shape[-2:] == (28, 28), \"Expect input shape to be (28, 28).\"\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nyxOM-RbZnC"
      },
      "source": [
        "## Implementing DDPM Forward and Inverse Process for Time-conditioned Denoising"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIvMw63T6JkE"
      },
      "outputs": [],
      "source": [
        "def ddpm_schedule(beta1: float, beta2: float, num_ts: int) -> dict:\n",
        "    \"\"\"Constants for DDPM training and sampling.\n",
        "\n",
        "    Arguments:\n",
        "        beta1: float, starting beta value.\n",
        "        beta2: float, ending beta value.\n",
        "        num_ts: int, number of timesteps.\n",
        "\n",
        "    Returns:\n",
        "        dict with keys:\n",
        "            betas: linear schedule of betas from beta1 to beta2.\n",
        "            alphas: 1 - betas.\n",
        "            alpha_bars: cumulative product of alphas.\n",
        "    \"\"\"\n",
        "    assert beta1 < beta2 < 1.0, \"Expect beta1 < beta2 < 1.0.\"\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfvtHEFf_7Q3"
      },
      "outputs": [],
      "source": [
        "def ddpm_forward(\n",
        "    unet: TimeConditionalUNet,\n",
        "    ddpm_schedule: dict,\n",
        "    x_0: torch.Tensor,\n",
        "    num_ts: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 1 of the DDPM paper.\n",
        "\n",
        "    Args:\n",
        "        unet: TimeConditionalUNet\n",
        "        ddpm_schedule: dict\n",
        "        x_0: (N, C, H, W) input tensor.\n",
        "        num_ts: int, number of timesteps.\n",
        "    Returns:\n",
        "        (,) diffusion loss.\n",
        "    \"\"\"\n",
        "    unet.train()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNE8-455IDm3"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def ddpm_sample(\n",
        "    unet: TimeConditionalUNet,\n",
        "    ddpm_schedule: dict,\n",
        "    img_wh: tuple[int, int],\n",
        "    num_ts: int,\n",
        "    seed: int = 0,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 2 of the DDPM paper with classifier-free guidance.\n",
        "\n",
        "    Args:\n",
        "        unet: TimeConditionalUNet\n",
        "        ddpm_schedule: dict\n",
        "        img_wh: (H, W) output image width and height.\n",
        "        num_ts: int, number of timesteps.\n",
        "        seed: int, random seed.\n",
        "\n",
        "    Returns:\n",
        "        (N, C, H, W) final sample.\n",
        "    \"\"\"\n",
        "    unet.eval()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_hVifFyw20j"
      },
      "outputs": [],
      "source": [
        "class DDPM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        unet: TimeConditionalUNet,\n",
        "        betas: tuple[float, float] = (1e-4, 0.02),\n",
        "        num_ts: int = 300,\n",
        "        p_uncond: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.unet = unet\n",
        "        self.num_ts = num_ts\n",
        "        self.p_uncond = p_uncond\n",
        "\n",
        "        self.ddpm_schedule = nn.ParameterDict(ddpm_schedule(betas[0], betas[1], num_ts))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "\n",
        "        Returns:\n",
        "            (,) diffusion loss.\n",
        "        \"\"\"\n",
        "        return ddpm_forward(\n",
        "            self.unet, self.ddpm_schedule, x, self.num_ts\n",
        "        )\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def sample(\n",
        "        self,\n",
        "        img_wh: tuple[int, int],\n",
        "        seed: int = 0,\n",
        "    ):\n",
        "        return ddpm_sample(\n",
        "            self.unet, self.ddpm_schedule, img_wh, self.num_ts, seed\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMYZt6IZTlSH"
      },
      "source": [
        "## Training the Time-conditioned UNet\n",
        "\n",
        "- Plot the loss curve\n",
        "- Sample results on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XIuV2xECTlSH",
        "outputId": "79089133-b9bc-4ec6-e35e-73441027491e"
      },
      "outputs": [],
      "source": [
        "dataset = MNIST(root='data', download=True, transform=ToTensor(), train=True)\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW2FBjpn8CTZ"
      },
      "source": [
        "### Implementing class-conditioned UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAXZYlOt8Rzy"
      },
      "outputs": [],
      "source": [
        "class ClassConditionalUNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        num_classes: int,\n",
        "        num_hiddens: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        c: torch.Tensor,\n",
        "        t: torch.Tensor,\n",
        "        mask: torch.Tensor | None = None,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "            c: (N,) int64 condition tensor.\n",
        "            t: (N,) normalized time tensor.\n",
        "            mask: (N,) mask tensor. If not None, mask out condition when mask == 0.\n",
        "\n",
        "        Returns:\n",
        "            (N, C, H, W) output tensor.\n",
        "        \"\"\"\n",
        "        assert x.shape[-2:] == (28, 28), \"Expect input shape to be (28, 28).\"\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NobmVh4U8BRP"
      },
      "outputs": [],
      "source": [
        "def ddpm_forward(\n",
        "    unet: ClassConditionalUNet,\n",
        "    ddpm_schedule: dict,\n",
        "    x_0: torch.Tensor,\n",
        "    c: torch.Tensor,\n",
        "    p_uncond: float,\n",
        "    num_ts: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 1 of the DDPM paper.\n",
        "\n",
        "    Args:\n",
        "        unet: ClassConditionalUNet\n",
        "        ddpm_schedule: dict\n",
        "        x_0: (N, C, H, W) input tensor.\n",
        "        c: (N,) int64 condition tensor.\n",
        "        p_uncond: float, probability of unconditioning the condition.\n",
        "        num_ts: int, number of timesteps.\n",
        "\n",
        "    Returns:\n",
        "        (,) diffusion loss.\n",
        "    \"\"\"\n",
        "    unet.train()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMW5YeCi8cqO"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def ddpm_sample(\n",
        "    unet: ClassConditionalUNet,\n",
        "    ddpm_schedule: dict,\n",
        "    c: torch.Tensor,\n",
        "    img_wh: tuple[int, int],\n",
        "    num_ts: int,\n",
        "    guidance_scale: float = 5.0,\n",
        "    seed: int = 0,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 2 of the DDPM paper with classifier-free guidance.\n",
        "\n",
        "    Args:\n",
        "        unet: ClassConditionalUNet\n",
        "        ddpm_schedule: dict\n",
        "        c: (N,) int64 condition tensor. Only for class-conditional\n",
        "        img_wh: (H, W) output image width and height.\n",
        "        num_ts: int, number of timesteps.\n",
        "        guidance_scale: float, CFG scale.\n",
        "        seed: int, random seed.\n",
        "\n",
        "    Returns:\n",
        "        (N, C, H, W) final sample.\n",
        "        (N, T_animation, C, H, W) caches.\n",
        "    \"\"\"\n",
        "    unet.eval()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdQFWwIt8mXh"
      },
      "outputs": [],
      "source": [
        "class DDPM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        unet: ClassConditionalUNet,\n",
        "        betas: tuple[float, float] = (1e-4, 0.02),\n",
        "        num_ts: int = 300,\n",
        "        p_uncond: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.unet = unet\n",
        "        self.betas = betas\n",
        "        self.num_ts = num_ts\n",
        "        self.p_uncond = p_uncond\n",
        "        self.ddpm_schedule = nn.ParameterDict(ddpm_schedule(betas[0], betas[1], num_ts))\n",
        "\n",
        "    def forward(self, x: torch.Tensor, c: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "            c: (N,) int64 condition tensor.\n",
        "\n",
        "        Returns:\n",
        "            (,) diffusion loss.\n",
        "        \"\"\"\n",
        "        return ddpm_forward(\n",
        "            self.unet, self.ddpm_schedule, x, c, self.p_uncond, self.num_ts\n",
        "        )\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def sample(\n",
        "        self,\n",
        "        c: torch.Tensor,\n",
        "        img_wh: tuple[int, int],\n",
        "        guidance_scale: float = 5.0,\n",
        "        seed: int = 0,\n",
        "    ):\n",
        "        return ddpm_sample(\n",
        "            self.unet, self.ddpm_schedule, c, img_wh, self.num_ts, guidance_scale, seed\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV-Sn617TlSJ"
      },
      "source": [
        "## Training the Class-conditioned UNet\n",
        "\n",
        "- Plot the loss curve\n",
        "- Sample results on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mh4Wt3ejTlSJ",
        "outputId": "e2f7b9fc-8150-4ffa-ebd8-56f364b6226d"
      },
      "outputs": [],
      "source": [
        "dataset = MNIST(root='data', download=True, transform=ToTensor(), train=True)\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "# TODO"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
